[
  {
    "subject_id": 2,
    "subject_name": "Neural Networks",
    "subject_code": "PCC-CSE-401-G",
    "branch": "CSE",
    "semester": 7,
    "exam_year": 2024,
    "full_pyq_text": "3533\nB.Tech. 7th Semester (CSE) (G-Scheme)\nExamination, December-2024\nNEURAL NETWORKS\nPaper - PCC-CSE-401G\nTime allowed: 3 hours\n[Maximum marks : 75]\nBefore answering the questions, candidates should ensure that they have been supplied the correct and complete question paper.\nNo complaint in this regard, will be entertained after examination.\nNote: Attempt five questions in all, selecting one question from each section. Question No. 1 is compulsory.\nAll questions carry equal marks.\n1. Explain the following:\n(a) Role of Dendrites and Axons in a Biological Neuron\n(b) Applications of Neural Network\n(c) Linear Separability\n(d) Supervised Learning\n(e) Generalized Delta Learning rule\n(f) Hetro Associative Memory\n2. Describe the structure of a biological neuron in detail and explain how its components contribute to signal processing and transmission.\n3. What are activation functions in artificial neural networks? Explain their role and importance with examples of threshold, sigmoid and tanh functions.\n4. Describe the McCulloch-Pitts (MCP) model in detail. Discuss its architecture, working and the solution for OR functions.\n5. Illustrate the concept of linear separability with the solution of the OR function.\n6. Describe the architecture of Backpropagation network. Discuss the training and testing processes in detail.\n7. Explain competitive learning. Discuss its applications and how it differs from conventional learning methods.\n8. What is Associative Memory? How does associative memory handle errors in data, such as missing or mistaken inputs? Discuss the mechanisms with examples.\n9. Explain Hebb model and implement logic 'AND' function using Hebb network."
  },
  {
    "subject_id": 2,
    "subject_name": "Neural Networks",
    "subject_code": "PCC-CSE-401-G",
    "branch": "CSE",
    "semester": 7,
    "exam_year": 2021,
    "full_pyq_text": "24489\nB.Tech. (CSE) 7th Semester Examination, March-2021\nNEURAL NETWORKS\nPaper-CSE-407-F\nTime: Three Hours\n[Maximum Marks: 100]\nBefore answering the questions, candidates should ensure that they have been supplied the correct and complete question paper.\nNo complaint in this regard, will be entertained after examination.\nNote:- Question No. 1 is compulsory. Attempt any five questions by selecting at least one question from each Section.\n1. Explain the following:\n(a) Perceptron learning rule\n(b) Weight initialization\n(c) Learning factors\n(d) Recall mode\n(e) Correction learning rule\n2. Explain Biological Neurons. Differentiate ANN and biological neurons with various learning factors.\nExplain feed forward and feedback networks with their learning rules.\n3. Explain MC Culloch-Pitts neuron to design logic networks of AND logic function with example.\nWrite short note on Widrow-Hoff learning rule.\n4. Explain single layer discrete perceptron training algorithm for linearly separable classification.\nExplain multilayer perceptron model for linearly non-separable pattern classification.\n5. Explain error back-propagation training algorithm.\nExplain Delta learning rule for multi-perceptron layer.\n6. Explain the various architecture of Hopfield network with training. How learning occurs in Hopfield network?\n7. Explain the associative memory with its various types in detail. Explain the encoding and decoding procedure in associative memory.\n8. Write short notes on the following: Unsupervised learning of clusters, Winner-take-all learning with algorithm.\n9. What is Competitive Learning? How is it different from conventional learning? Discuss its significance and usefulness in neural networks."
  },
  {
    "subject_id": 2,
    "subject_name": "Neural Networks",
    "subject_code": "PCC-CSE-401-G",
    "branch": "CSE",
    "semester": 7,
    "exam_year": 2022,
    "full_pyq_text": "B.Tech. (CSE) 7th Semester (G-Scheme)\nExamination, December-2022\nNEURAL NETWORKS\nPaper - PCC-CSE-401-G\n[Maximum marks: 75]\nTime allowed: 3 hours\nNote: All questions carry equal marks. Question no. 1 is compulsory. In addition to the compulsory question, student will have to attempt four more questions selecting one question from each unit.\n1. Discuss evolution of neural network.\nExplain the Competitive Learning.\nObtain the output of neuron Y neuron having three input x1=1, x2=2, and x3=3 and weight are w1=1, w2=1, w3=2 by using Threshold and Sigmodial activation functions.\nDiscuss the concept of Storage capacity in Associative Memory.\nUnit I: Explain the component of a Biological Neuron. Also focus on Biological neuron equivalencies to artificial neuron model.\nWhat is Activation Function? Why it is used? Give different types of activation function in detail.\nUnit II: What is perceptron? Also realize if for OR function for bipolar data. Explain Linear Separability Concept by taking a suitable example, also classify the output of OR function using it.\nUnit III: Derive Gradient Decent algorithm and compare it with generalized delta learning rule. What is Learning? Explain its different types.\nUnit IV: Store the vector [1 1 -1 -1] in Auto Associative Network, And find Weight Matrix, Test the net with input vector, Test with one mistake in input, Test with one missing in input, Test with two missing in input, Test with two mistake in input.\nExplain Auto Associative Memory with its architecture, training (insertion) and testing (Retrieval) Algorithm."
  },
  {
    "subject_id": 2,
    "subject_name": "Neural Networks",
    "subject_code": "PCC-CSE-401-G",
    "branch": "CSE",
    "semester": 7,
    "exam_year": 2023,
    "full_pyq_text": "B.Tech. 7th Semester (CSE) Examination â€“ May, 2023\nNEURAL NETWORKS\nPaper: PCC-CSE-401-G\nTime: Three hours [Maximum Marks: 75]\nBefore answering the questions, candidates should ensure that they have been supplied the correct and complete question paper.\nNote: Attempt five questions in all, selecting one question from each Section. Question No. 1 is compulsory. All questions carries equal marks.\n1. Explain the following: Application of Neural Networks, Activation Function, Describe Learning Factors, Structure of Biological Neuron, Auto Associative Memory, Hetro Associative Memory.\n2. Explain architecture of artificial Neural Network. Explain its three basic types of Neuron connection architecture.\n3. What is associative memory? Explain its various types in detail with suitable example.\n4. What do you mean by McCulloch Pitts Model? Explain this model by using AND function.\n5. Explain the following: Gradient Descent Algorithm, Linear Separability.\n6. Explain Single Layer architecture of Perceptron Network and implement AND Function using Perceptron Network.\n7. Describe the following: Supervised Learning, Unsupervised Learning, Reinforcement Learning.\n8. Explain Hebb Model in detail.\n9. What is Competitive Learning? How it is different from conventional Learning? Explain its significance and usefulness in Neural Network."
  }
]
